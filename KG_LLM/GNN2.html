<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* --- INTEGRATED CRT CORE STYLES --- */
        :root {
            --bg-color: #000000;
            --text-color: #00ff41;
            --accent-color: #00ff41;
            --dim-color: #003b00;
            --border-color: #00ff41;
            --font-main: 'Courier New', Courier, monospace;
            --font-header: 'Arial Black', Impact, sans-serif;
            --crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--font-main);
            margin: 0;
            padding: 20px;
            line-height: 1.5;
        }

        .dither-layer {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
            background-size: 4px 4px;
            opacity: 0.4;
        }

        .scanlines {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
            background-size: 100% 4px;
            pointer-events: none;
            z-index: 9999;
        }

        strong { color: var(--accent-color); text-decoration: underline; }
        em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

        details.section {
            margin-bottom: 15px;
            border: 1px solid var(--dim-color);
            background: #050505;
        }

        details.section > summary {
            font-weight: bold;
            padding: 12px;
            background: #0a0a0a;
            cursor: pointer;
            list-style: none;
            text-transform: uppercase;
            font-size: 1.1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        details.section[open] > summary {
            border-bottom: 1px solid var(--dim-color);
            color: var(--accent-color);
            text-shadow: var(--crt-glow);
        }

        .section-content { padding: 20px; }

        .subsection {
            margin-bottom: 30px;
            border-left: 4px solid var(--dim-color);
            padding-left: 15px;
        }

        .subsection-title {
            background: var(--dim-color);
            color: var(--accent-color);
            padding: 4px 10px;
            font-weight: bold;
            text-transform: uppercase;
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            font-size: 0.95rem;
        }

        .code-block {
            background: #020a02;
            border: 1px dashed var(--dim-color);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.85rem;
            color: var(--accent-color);
            overflow-x: auto;
        }

        .eye-btn {
            background: none;
            border: 1px solid var(--accent-color);
            color: var(--accent-color);
            cursor: pointer;
            padding: 2px 5px;
            display: flex;
            align-items: center;
            opacity: 0.7;
        }
        .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
    </style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
    <summary>
        PREPROCESSING AND ENCODER-DECODERS FOR NODE CLASSIFICATION:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                PRE-PROCESSING:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>1. Node-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Incremental Re-indexing:</strong> Maps sparse identifiers (like IP addresses) to dense, zero-indexed integers.<br>
                <em>Useful & Why:</em> Essential for memory efficiency. It creates a contiguous address block for embeddings, preventing the allocation of massive, empty tensors for non-existent IDs.</li>
                <li><strong>Feature Normalization:</strong> Scales numerical node features using Z-score or Min-Max scaling.<br>
                <em>Useful & Why:</em> Critical for convergence. It prevents features with large magnitudes (like "account balance") from exploding gradients and dominating the learning process.</li>
                <li><strong>Positional Encodings:</strong> Injects structural coordinates (like Laplacian Eigenvectors) into node features.<br>
                <em>Useful & Why:</em> Vital for structure-aware tasks. It allows the model to distinguish between topologically identical subgraphs based on their absolute position in the global graph.</li>
            </ul>

            <p><strong>2. Edge-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Adjacency List Construction:</strong> Converts known positive connections into a compact Coordinate (COO) format.<br>
                <em>Useful & Why:</em> Foundational for computation. It transforms raw source-target pairs into the sparse matrix standard required for optimized GPU message passing.</li>
                <li><strong>Negative Sampling:</strong> Randomly generates "fake" edges (node pairs that do not connect).<br>
                <em>Useful & Why:</em> Mandatory for discriminative learning. Without "fake" examples (Class 0), the model only sees positives (Class 1) and collapses to a trivial "always true" solution.</li>
                <li><strong>Edge Weighting:</strong> Assigns values to existing links based on interaction strength.<br>
                <em>Useful & Why:</em> Adds necessary nuance. It helps the model prioritize significant, high-traffic pathways over weak or incidental connections in dense graphs.</li>
            </ul>

            <p><strong>3. Structural & Task-Specific Methods</strong></p>
            <ul>
                <li><strong>Subgraph Sampling (e.g., SEAL):</strong> Extracts localized subgraphs around target edge pairs.<br>
                <em>Useful & Why:</em> Enables scaling. It allows training on massive datasets (like social networks) by processing manageable local neighborhoods instead of the entire graph at once.</li>
                <li><strong>Virtual Nodes:</strong> Adds a global dummy node connected to all real nodes.<br>
                <em>Useful & Why:</em> Shortcuts long paths. It allows distant nodes to communicate instantly, improving performance on graphs with long chains or disconnected components.</li>
            </ul>

            <p><strong>4. Edge Splitting & Masking (The Final Phase)</strong></p>
            <ul>
                <li><strong>Message-Passing vs. Supervision Edges:</strong> "Message-passing" edges build the topology; "supervision" edges are hidden for loss calculation.<br>
                <em>Useful & Why:</em> Prevents data leakage. It ensures the model predicts links based on surrounding context, rather than "cheating" by seeing the target link in the input graph.</li>
                <li><strong>Edge Splits (Train/Val/Test):</strong> Positive and negative edges are strictly partitioned.<br>
                <em>Useful & Why:</em> Standard validation. It segregates data to verify the model is learning generalizable patterns rather than simply memorizing the training graph structure.</li>
                <li><strong>Class Balancing:</strong> Ensures a controlled ratio (often 1:1) of positive (real) to negative (fake) edges.<br>
                <em>Useful & Why:</em> Corrects statistical bias. It prevents the model from achieving high accuracy metrics by simply guessing "no link" for every pair in a sparse graph.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR NODE CLASSIFICATION:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>The Foundation: BaseGraphModel</strong></p>
            <p>A template class defining a standard two-layer message-passing flow. It takes a specific convolution layer (like SAGEConv) as an argument and automatically applies a ReLU activation between layers.</p>
            <ul>
                <li><em>How it works:</em> It uses dependency injection. You hand it a "type" of convolution (like a constructor), and it builds the layers for you. This ensures that every model you build follows the same connectivity pattern and dropout rules.</li>
                <li><em>When to use / Why:</em> Use when building multiple GNN architectures. It standardizes the forward pass and reduces boilerplate code across different convolution experiments.</li>
            </ul>
        
            <p><strong>The Simple Implementation: SAGE</strong></p>
            
            <p>GraphSAGE (Sample and Aggregate) plugs directly into the base template. It inherits the structural logic and simply passes SAGEConv as the chosen layer.</p>
            <ul>
                <li><em>How it works:</em> It aggregates features from a fixed-size sample of a node’s neighborhood (e.g., "only look at 10 random friends"). It then concatenates the node's own features with this neighborhood summary. This makes the computation time predictable regardless of how "popular" a node is.</li>
                <li><em>When to use / Why:</em> Use for large, dense graphs. It scales efficiently by sampling fixed-size neighborhoods instead of processing every single connection a node has.</li>
            </ul>
        
            <p><strong>The Custom Implementation: GAT</strong></p>
            
            <p>Graph Attention Networks require custom parameters like attention "heads." GAT manually overrides the constructor to define its layers, multiplying the hidden dimension by the number of attention heads.</p>
            <ul>
                <li><em>How it works:</em> It uses an Attention Mechanism to assign a coefficient (a weight) to every edge. It also uses "Multi-Head Attention," where the model runs several independent attention processes at once (like having 8 different experts looking at the same neighborhood) and then combines their findings.</li>
                <li><em>When to use / Why:</em> Use when edge weights matter but aren't explicitly provided. Attention heads learn which neighbors are most important for the specific task.</li>
            </ul>
        
            <p><strong>Integration: NodeClassifier (The Encoder)</strong></p>
            
            <p>The encoder wraps the chosen model to perform recursive aggregation. Layer 1 captures immediate neighbors. Layer 2 aggregates those results, allowing the center node to "see" a 2-hop radius.</p>
            <ul>
                <li><em>When to use / Why:</em> Use as the core engine for learning topology. It systematically transforms raw node features and local connections into dense, mathematically useful embeddings.</li>
            </ul>
        
            <p><strong>The Decoder: Logarithmic Mapping</strong></p>
            <p>For multi-class node classification, the standard decoder is log_softmax. It outputs a log-probability for each node, optimized using NLLLoss.</p>
            <ul>
                <li><em>When to use / Why:</em> Use for standard multi-class node classification. Operating in log-space stabilizes gradient descent and prevents underflow with extreme probabilities.</li>
            </ul>
        
            <p><strong>Other Decoders for Node Classification Tasks:</strong></p>
            <ul>
                <li><strong>Binary Classification (Sigmoid):</strong> Used for true/false states (e.g., fraudulent vs. legitimate). Outputs a single 0-1 scalar. Optimized with BCELoss.<br>
                <em>When to use / Why:</em> Use for simple A/B sorting. It squashes output to a 0-1 probability score, perfectly pairing with binary cross-entropy loss.</li>
                
                <li><strong>Multi-Label Classification (Independent Sigmoid):</strong> Used when a node belongs to multiple, overlapping categories. Outputs a probability vector. Optimized with BCEWithLogitsLoss.<br>
                <em>When to use / Why:</em> Use when categories overlap (e.g., an entity is both a buyer and seller). It evaluates each class independently rather than forcing a single choice.</li>
                
                <li><strong>Node Regression (Identity/Linear):</strong> Used to predict continuous, real-valued numbers (raw logits). Optimized with MSELoss or L1Loss.<br>
                <em>When to use / Why:</em> Use for predicting continuous metrics (e.g., transaction volume). It passes the raw numerical output directly to calculate absolute error.</li>
                
                <li><strong>Clustering/Unsupervised (Inner Product):</strong> Used without labels. It calculates the dot product of two node embeddings.<br>
                <em>When to use / Why:</em> Use when labels are missing. It forces nodes with similar structural roles or communities to cluster tightly together in the latent embedding space.</li>
            </ul>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        ENCODER-DECODERS FOR LINK PREDICTION
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR LINK PREDICTION WALKTHROUGH:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>Phase 1: Global Identity Normalization (Indexing)</strong></p>
            <p>Maps raw entity names (like emails or hashes) to contiguous, zero-indexed integers so the GPU can locate them directly in memory. Ecosystems expand this using fast hash functions (like MurmurHash) to convert strings on the fly.</p>
            <ul>
                <li><em>How it works:</em> It assigns every unique raw identifier a sequential integer ID starting from zero. For streaming data, hash functions deterministically map incoming strings to these integer addresses instantly without needing a pre-built static dictionary.</li>
                <li><em>When to use / Why:</em> Use as the mandatory first step for graph building. GPUs cannot process raw strings or sparse, non-sequential IDs. It ensures contiguous memory allocation, preventing massive, empty, and crash-inducing tensors.</li>
            </ul>

            <p><strong>Phase 2: Structural Encoding (edge_index)</strong></p>
            
            <p>Stores graph topology in a 2D tensor (COO format), cleanly separating a node's connections from its actual data features. Advanced setups convert this to CSR formats for extreme speed.</p>
            <ul>
                <li><em>How it works:</em> It creates a 2-by-E matrix where the first row holds source node IDs and the second row holds target node IDs. This Coordinate (COO) format efficiently lists only the edges that actually exist, rather than an N-by-N matrix full of zeros.</li>
                <li><em>When to use / Why:</em> Use for foundational message passing. COO is the standard for PyTorch Geometric to route information between nodes. Converting to CSR is used later when aggressively optimizing dense matrix multiplications in production.</li>
            </ul>

            <p><strong>Phase 3: Feature Matrix Alignment (X)</strong></p>
            
            <p>Ensures strict 1:1 mapping between a node’s new integer ID and its specific row in the dense feature matrix tensor. These vectors can be enriched via PageRank or LLM semantic embeddings.</p>
            <ul>
                <li><em>How it works:</em> It constructs a master feature tensor where row i contains the specific attributes for the node assigned integer ID i. This perfectly aligns the topological map (the edge_index) with the actual node characteristics (the features).</li>
                <li><em>When to use / Why:</em> Use to give the model actual data to learn from beyond just the graph structure. Perfect alignment is critical; a mismatch here means the network is learning from scrambled, incorrect node profiles, rendering the embeddings useless.</li>
            </ul>

            <p><strong>Phase 4: Dataset Splitting & Edge Masking</strong></p>
            
            <p>Hides real "positive" edges for testing, and generates fake "negative" edges so the model learns what non-connections look like. Advanced setups use TemporalData to prevent time-based leaks.</p>
            <ul>
                <li><em>How it works:</em> It splits edges into message-passing (to build the graph) and supervision (to calculate loss). Crucially, it samples random pairs of unconnected nodes to act as negative examples, giving the model a balanced 1:1 classification task.</li>
                <li><em>When to use / Why:</em> Use because real graphs only list positive links. Without generating negative samples, the model collapses into trivially predicting every node pair is connected. Hard negative mining forces the model to learn finer, more accurate boundaries.</li>
            </ul>

            <p><strong>Phase 5: Mini-Batching (Subgraph Generation)</strong></p>
            
            <p>Uses breadth-first search to extract small, localized multi-hop subgraphs, allowing huge networks to fit into GPU memory. Systems use METIS or random walks to control size.</p>
            <ul>
                <li><em>How it works:</em> It pulls a target edge and recursively samples its multi-hop neighborhood to create a self-contained mini-graph. To prevent exponential "neighbor explosion," techniques like GraphSAINT use random walks to strictly bound the subgraph size.</li>
                <li><em>When to use / Why:</em> Use when your graph is too large to fit into VRAM. Standard batching doesn't work for graphs because nodes are connected; subgraph batching preserves the necessary local topology so the model can still aggregate neighbor messages accurately.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                HETEROGENOUS ENCODERS:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>In a homogeneous GNN, the model uses one weight matrix. In a heterogeneous graph, the encoder maintains separate weight matrices for each relationship type to process different kinds of nodes effectively.</p>
            
            <p><strong>ENCODING APPROACHES:</strong></p>
        
            <p><strong>1. Identity-based (Lookup Tables)</strong></p>
            
            <p>Assigns a unique, trainable vector to every individual entity. A matrix stores one vector per ID.</p>
            <ul>
                <li><em>How it works:</em> It creates an embedding matrix where each row corresponds to a specific node ID. Meaning is derived purely from structural context: if Node A (User) interacts with Node B (Movie), the loss function forces their two vectors to move closer together in mathematical space. If Node A and Node C both interact with Node B, their vectors eventually become similar. They "know" they are alike not because they share raw features, but because they share a neighbor.</li>
                <li><em>When to use / Why:</em> Use for massive Collaborative Filtering where metadata is scarce. It excels when you have vast interaction logs (like clicks or purchases) but lack descriptive features (like age or genre). It effectively allows the model to "learn" a node's reputation through its social or transactional history rather than its resume.</li>
            </ul>
        
            <p><strong>2. Feature-based (Linear/MLP Projections)</strong></p>
            
            <p>Transforms raw attributes (age, price) into a vector space using a Linear layer or MLP.</p>
            <ul>
                <li><em>How it works:</em> It ignores node IDs entirely and passes a node's raw metadata through a neural network. The network projects these attributes into a dense embedding space, mathematically capturing "what" the entity is based purely on its inherent properties.</li>
                <li><em>When to use / Why:</em> Use for "cold-start" scenarios. When a new user or item enters the system with zero interaction history, identity-based methods fail. This method relies entirely on known properties to generate a useful initial embedding.</li>
            </ul>
        
            <p><strong>3. Hybrid Fusion (The "Two-Step")</strong></p>
            <p>Merges Identity and Feature methods. Concatenates the "what" (feature) to the "who" (identity).</p>
            <ul>
                <li><em>How it works:</em> It calculates an identity embedding (from a lookup table) and a feature embedding (from an MLP) independently. It then concatenates or adds these two vectors together, creating a unified representation that captures both historical behavior and static traits.</li>
                <li><em>When to use / Why:</em> Use for modern Recommendation Systems needing a "warm start." It offers the best of both worlds, providing highly expressive embeddings for active users while maintaining a baseline representation for newer entities based on their features.</li>
            </ul>
        
            <p><strong>4. Contextual/Sequential Encoders</strong></p>
            
            <p>Models like RNNs or Transformers process sequences of past actions.</p>
            <ul>
                <li><em>How it works:</em> Instead of treating a user's history as an unordered pile of interactions, it feeds the chronological sequence of their actions into a recurrent network or self-attention mechanism. This captures the temporal evolution of their behavior over time.</li>
                <li><em>When to use / Why:</em> Use for session-based recommendations. It is critical when the specific order and recency of actions dictate the next step, such as predicting the next item a user will add to a shopping cart during an active browsing session.</li>
            </ul>
        
            <p><strong>HETEROGENEOUS DECODERS:</strong></p>
            <p>Once nodes are encoded, the decoder is responsible for calculating the probability or strength of a relationship between them.</p>
        
            <p><strong>1. Dot Product (Similarity-Based)</strong></p>
            
            <p>Computes similarity between user and item vectors.</p>
            <ul>
                <li><em>How it works:</em> It calculates the inner product between two node embeddings. Geometrically, this measures how closely aligned the two vectors are in the latent space. A higher dot product translates to a higher predicted probability of a link or interaction.</li>
                <li><em>When to use / Why:</em> Use for large-scale retrieval. It is highly computationally efficient, making it the standard choice for quickly scoring millions of potential candidate pairs in the first stage of a recommendation pipeline.</li>
            </ul>
        
            <p><strong>2. Multi-Layer Perceptron (MLP) (Non-Linear)</strong></p>
            <p>Concatenates embeddings and passes them through a neural network.</p>
            <ul>
                <li><em>How it works:</em> It takes the source and target node embeddings, concatenates them into a single long vector, and feeds that through several hidden layers with non-linear activations. The network outputs a final interaction probability score.</li>
                <li><em>When to use / Why:</em> Use for high-precision ranking. It captures complex, non-linear interactions between entities that a simple dot product would miss, making it ideal for the final, computationally heavier scoring stage of a recommendation system.</li>
            </ul>
        
            <p><strong>3. TransE (Translational Distance)</strong></p>
            
            <p>Treats relationship as translation: h + r ≈ t.</p>
            <ul>
                <li><em>How it works:</em> It embeds nodes (head/tail) and relationship types as vectors in the same space. It assumes that if a fact is true, adding the relationship vector to the head node vector should land exactly on the tail node vector in the latent space.</li>
                <li><em>When to use / Why:</em> Use for Knowledge Graphs with strict logical flow. It is highly effective at modeling 1-to-1 relationships and capturing hierarchical or directional facts (e.g., "Rome" + "is capital of" ≈ "Italy").</li>
            </ul>
        
            <p><strong>4. DistMult (Multiplicative Interaction)</strong></p>
            
            <p>Relationship as diagonal matrix M_r. Score = h_i^T M_r h_j.</p>
            <ul>
                <li><em>How it works:</em> It embeds nodes as vectors and relationship types as diagonal matrices. It computes an element-wise multiplication between the head vector, the relationship matrix, and the tail vector, weighting the interaction by the specific relationship type.</li>
                <li><em>When to use / Why:</em> Use for Knowledge Graphs with symmetrical relationships. It is highly efficient and captures multi-relational semantics well, though its symmetric nature makes it less suitable for strictly directional relationships compared to TransE.</li>
            </ul>
        </div>
        </div>
        </details>
</body>
</html>