<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* --- INTEGRATED CRT CORE STYLES --- */
        :root {
            --bg-color: #000000;
            --text-color: #00ff41;
            --accent-color: #00ff41;
            --dim-color: #003b00;
            --border-color: #00ff41;
            --font-main: 'Courier New', Courier, monospace;
            --font-header: 'Arial Black', Impact, sans-serif;
            --crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--font-main);
            margin: 0;
            padding: 20px;
            line-height: 1.5;
        }

        .dither-layer {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
            background-size: 4px 4px;
            opacity: 0.4;
        }

        .scanlines {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
            background-size: 100% 4px;
            pointer-events: none;
            z-index: 9999;
        }

        strong { color: var(--accent-color); text-decoration: underline; }
        em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

        details.section {
            margin-bottom: 15px;
            border: 1px solid var(--dim-color);
            background: #050505;
        }

        details.section > summary {
            font-weight: bold;
            padding: 12px;
            background: #0a0a0a;
            cursor: pointer;
            list-style: none;
            text-transform: uppercase;
            font-size: 1.1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        details.section[open] > summary {
            border-bottom: 1px solid var(--dim-color);
            color: var(--accent-color);
            text-shadow: var(--crt-glow);
        }

        .section-content { padding: 20px; }

        .subsection {
            margin-bottom: 30px;
            border-left: 4px solid var(--dim-color);
            padding-left: 15px;
        }

        .subsection-title {
            background: var(--dim-color);
            color: var(--accent-color);
            padding: 4px 10px;
            font-weight: bold;
            text-transform: uppercase;
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            font-size: 0.95rem;
        }

        .code-block {
            background: #020a02;
            border: 1px dashed var(--dim-color);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.85rem;
            color: var(--accent-color);
            overflow-x: auto;
        }

        .eye-btn {
            background: none;
            border: 1px solid var(--accent-color);
            color: var(--accent-color);
            cursor: pointer;
            padding: 2px 5px;
            display: flex;
            align-items: center;
            opacity: 0.7;
        }
        .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
    </style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
    <summary>
        PREPROCESSING AND ENCODER-DECODERS FOR NODE CLASSIFICATION:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                PRE-PROCESSING:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>1. Node-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Incremental Re-indexing:</strong> Maps sparse identifiers (like IP addresses) to dense, zero-indexed integers.<br>
                <em>Useful & Why:</em> Essential for memory efficiency. It creates a contiguous address block for embeddings, preventing the allocation of massive, empty tensors for non-existent IDs.</li>
                <li><strong>Feature Normalization:</strong> Scales numerical node features using Z-score or Min-Max scaling.<br>
                <em>Useful & Why:</em> Critical for convergence. It prevents features with large magnitudes (like "account balance") from exploding gradients and dominating the learning process.</li>
                <li><strong>Positional Encodings:</strong> Injects structural coordinates (like Laplacian Eigenvectors) into node features.<br>
                <em>Useful & Why:</em> Vital for structure-aware tasks. It allows the model to distinguish between topologically identical subgraphs based on their absolute position in the global graph.</li>
            </ul>

            <p><strong>2. Edge-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Adjacency List Construction:</strong> Converts known positive connections into a compact Coordinate (COO) format.<br>
                <em>Useful & Why:</em> Foundational for computation. It transforms raw source-target pairs into the sparse matrix standard required for optimized GPU message passing.</li>
                <li><strong>Negative Sampling:</strong> Randomly generates "fake" edges (node pairs that do not connect).<br>
                <em>Useful & Why:</em> Mandatory for discriminative learning. Without "fake" examples (Class 0), the model only sees positives (Class 1) and collapses to a trivial "always true" solution.</li>
                <li><strong>Edge Weighting:</strong> Assigns values to existing links based on interaction strength.<br>
                <em>Useful & Why:</em> Adds necessary nuance. It helps the model prioritize significant, high-traffic pathways over weak or incidental connections in dense graphs.</li>
            </ul>

            <p><strong>3. Structural & Task-Specific Methods</strong></p>
            <ul>
                <li><strong>Subgraph Sampling (e.g., SEAL):</strong> Extracts localized subgraphs around target edge pairs.<br>
                <em>Useful & Why:</em> Enables scaling. It allows training on massive datasets (like social networks) by processing manageable local neighborhoods instead of the entire graph at once.</li>
                <li><strong>Virtual Nodes:</strong> Adds a global dummy node connected to all real nodes.<br>
                <em>Useful & Why:</em> Shortcuts long paths. It allows distant nodes to communicate instantly, improving performance on graphs with long chains or disconnected components.</li>
            </ul>

            <p><strong>4. Edge Splitting & Masking (The Final Phase)</strong></p>
            <ul>
                <li><strong>Message-Passing vs. Supervision Edges:</strong> "Message-passing" edges build the topology; "supervision" edges are hidden for loss calculation.<br>
                <em>Useful & Why:</em> Prevents data leakage. It ensures the model predicts links based on surrounding context, rather than "cheating" by seeing the target link in the input graph.</li>
                <li><strong>Edge Splits (Train/Val/Test):</strong> Positive and negative edges are strictly partitioned.<br>
                <em>Useful & Why:</em> Standard validation. It segregates data to verify the model is learning generalizable patterns rather than simply memorizing the training graph structure.</li>
                <li><strong>Class Balancing:</strong> Ensures a controlled ratio (often 1:1) of positive (real) to negative (fake) edges.<br>
                <em>Useful & Why:</em> Corrects statistical bias. It prevents the model from achieving high accuracy metrics by simply guessing "no link" for every pair in a sparse graph.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR NODE CLASSIFICATION:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>The Foundation: BaseGraphModel</strong></p>
            <p>A template class defining a standard two-layer message-passing flow. It takes a specific convolution layer (like SAGEConv) as an argument and automatically applies a ReLU activation between layers.</p>
            <ul>
                <li><em>How it works:</em> It uses dependency injection. You hand it a "type" of convolution (like a constructor), and it builds the layers for you. This ensures that every model you build follows the same connectivity pattern and dropout rules.</li>
                <li><em>When to use / Why:</em> Use when building multiple GNN architectures. It standardizes the forward pass and reduces boilerplate code across different convolution experiments.</li>
            </ul>
        
            <p><strong>The Simple Implementation: SAGE</strong></p>
            
            <p>GraphSAGE (Sample and Aggregate) plugs directly into the base template. It inherits the structural logic and simply passes SAGEConv as the chosen layer.</p>
            <ul>
                <li><em>How it works:</em> It aggregates features from a fixed-size sample of a node’s neighborhood (e.g., "only look at 10 random friends"). It then concatenates the node's own features with this neighborhood summary. This makes the computation time predictable regardless of how "popular" a node is.</li>
                <li><em>When to use / Why:</em> Use for large, dense graphs. It scales efficiently by sampling fixed-size neighborhoods instead of processing every single connection a node has.</li>
            </ul>
        
            <p><strong>The Custom Implementation: GAT</strong></p>
            
            <p>Graph Attention Networks require custom parameters like attention "heads." GAT manually overrides the constructor to define its layers, multiplying the hidden dimension by the number of attention heads.</p>
            <ul>
                <li><em>How it works:</em> It uses an Attention Mechanism to assign a coefficient (a weight) to every edge. It also uses "Multi-Head Attention," where the model runs several independent attention processes at once (like having 8 different experts looking at the same neighborhood) and then combines their findings.</li>
                <li><em>When to use / Why:</em> Use when edge weights matter but aren't explicitly provided. Attention heads learn which neighbors are most important for the specific task.</li>
            </ul>
        
            <p><strong>Integration: NodeClassifier (The Encoder)</strong></p>
            
            <p>The encoder wraps the chosen model to perform recursive aggregation. Layer 1 captures immediate neighbors. Layer 2 aggregates those results, allowing the center node to "see" a 2-hop radius.</p>
            <ul>
                <li><em>When to use / Why:</em> Use as the core engine for learning topology. It systematically transforms raw node features and local connections into dense, mathematically useful embeddings.</li>
            </ul>
        
            <p><strong>The Decoder: Logarithmic Mapping</strong></p>
            <p>For multi-class node classification, the standard decoder is log_softmax. It outputs a log-probability for each node, optimized using NLLLoss.</p>
            <ul>
                <li><em>When to use / Why:</em> Use for standard multi-class node classification. Operating in log-space stabilizes gradient descent and prevents underflow with extreme probabilities.</li>
            </ul>
        
            <p><strong>Other Decoders for Node Classification Tasks:</strong></p>
            <ul>
                <li><strong>Binary Classification (Sigmoid):</strong> Used for true/false states (e.g., fraudulent vs. legitimate). Outputs a single 0-1 scalar. Optimized with BCELoss.<br>
                <em>When to use / Why:</em> Use for simple A/B sorting. It squashes output to a 0-1 probability score, perfectly pairing with binary cross-entropy loss.</li>
                
                <li><strong>Multi-Label Classification (Independent Sigmoid):</strong> Used when a node belongs to multiple, overlapping categories. Outputs a probability vector. Optimized with BCEWithLogitsLoss.<br>
                <em>When to use / Why:</em> Use when categories overlap (e.g., an entity is both a buyer and seller). It evaluates each class independently rather than forcing a single choice.</li>
                
                <li><strong>Node Regression (Identity/Linear):</strong> Used to predict continuous, real-valued numbers (raw logits). Optimized with MSELoss or L1Loss.<br>
                <em>When to use / Why:</em> Use for predicting continuous metrics (e.g., transaction volume). It passes the raw numerical output directly to calculate absolute error.</li>
                
                <li><strong>Clustering/Unsupervised (Inner Product):</strong> Used without labels. It calculates the dot product of two node embeddings.<br>
                <em>When to use / Why:</em> Use when labels are missing. It forces nodes with similar structural roles or communities to cluster tightly together in the latent embedding space.</li>
            </ul>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        ENCODER-DECODERS FOR LINK PREDICTION
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR LINK PREDICTION WALKTHROUGH:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>Phase 1: Global Identity Normalization (Indexing)</strong></p>
            <p>The Core: Mapping arbitrary entity names into a continuous 0-indexed integer space for direct GPU memory addressing. Ecosystem Expansion: Beyond basic dictionary mapping, massive streaming graphs use hash functions (e.g., MurmurHash) to convert strings to integers on the fly.</p>
            
            <p><strong>Phase 2: Structural Encoding (the edge_index)</strong></p>
            <p>The Core: Storing network topology in a 2 × E Coordinate (COO) tensor to separate “who a node knows” from “what a node is.” Ecosystem Expansion: While COO is standard, tools like <em>scipy.sparse</em> offer CSR (Compressed Sparse Row) formats, which are vastly superior for high-performance matrix multiplications.</p>

            <p><strong>Phase 3: Feature Matrix Alignment (X)</strong></p>
            <p>The Core: Creating a 1:1 correspondence between a node’s integer ID and its row in the dense feature matrix. Ecosystem Expansion: Features (X) can be generated using algorithms like PageRank or dense vector embeddings via LLMs (semantic text chunking) prior to alignment.</p>

            <p><strong>Phase 4: Dataset Splitting & Edge Masking</strong></p>
            <p>The Core: Hiding ground-truth positive edges and generating fake “negative” edges. Ecosystem Expansion: Tools like PyG’s <em>TemporalData</em> ensure models don’t predict the past using future edges. Hard Negative Mining frameworks select highly plausible but fake edges to force finer decision boundaries.</p>

            <p><strong>Phase 5: Mini-Batching (Subgraph Generation)</strong></p>
            <p>The Core: Using breadth-first expansion to extractLocalized, multi-hop subgraphs. Ecosystem Expansion: <em>Cluster-GCN</em> uses METIS to partition graphs. <em>GraphSAINT</em> samples random walks to neutralize “neighbor explosion.”</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                —HETEROGENOUS ENCODERS—
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>In a homogeneous GNN, the model uses one weight matrix. In a heterogeneous graph, the encoder maintains separate weight matrices for each relationship type.</p>
            
            <p><strong>ENCODING APPROACHES:</strong></p>
            <ul>
                <li><strong>1. Identity-based (Lookup Tables):</strong> Assigns a unique, trainable vector to every individual entity. matrix stores one vector per ID. Use this for large-scale Collaborative Filtering with little metadata.</li>
                <li><strong>2. Feature-based (Linear/MLP Projections):</strong> Transforms raw attributes (age, price) into a vector space using a Linear layer or MLP. Appropriate for cold-start scenarios.</li>
                <li><strong>3. Hybrid Fusion (The "Two-Step"):</strong> Merges Identity and Feature methods. Concatenates the "what" (feature) to the "who" (identity). Appropriate for RecSys needing a "warm start."</li>
                <li><strong>4. Contextual/Sequential Encoders:</strong> Models like RNNs or Transformers process sequences of past actions. Use this for session-based recommendations.</li>
            </ul>

            <p><strong>DECODER APPROACHES:</strong></p>
            <ul>
                <li><strong>1. Dot Product (Similarity-Based):</strong> Computes similarity between user and item vectors. Critical for large-scale retrieval efficiency.</li>
                <li><strong>2. Multi-Layer Perceptron (MLP) (Non-Linear):</strong> Concatenates embeddings and passes them through a neural network. Used for high-precision ranking.</li>
                <li><strong>3. TransE (Translational Distance):</strong> Treats relationship as translation: h + r ≈ t. Ideal for knowledge graphs with logical flow.</li>
                <li><strong>4. DistMult (Multiplicative Interaction):</strong> Relationship as diagonal matrix M_r. Score = h_i^T M_r h_j. Performs element-wise multiplication weighted by relationship importance.</li>
            </ul>
        </div>
    </div>
</details>

</body>
</html>