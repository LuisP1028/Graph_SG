<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* --- INTEGRATED CRT CORE STYLES --- */
        :root {
            --bg-color: #000000;
            --text-color: #00ff41;
            --accent-color: #00ff41;
            --dim-color: #003b00;
            --border-color: #00ff41;
            --font-main: 'Courier New', Courier, monospace;
            --font-header: 'Arial Black', Impact, sans-serif;
            --crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--font-main);
            margin: 0;
            padding: 20px;
            line-height: 1.5;
        }

        .dither-layer {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
            background-size: 4px 4px;
            opacity: 0.4;
        }

        .scanlines {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
            background-size: 100% 4px;
            pointer-events: none;
            z-index: 9999;
        }

        strong { color: var(--accent-color); text-decoration: underline; }
        em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

        details.section {
            margin-bottom: 15px;
            border: 1px solid var(--dim-color);
            background: #050505;
        }

        details.section > summary {
            font-weight: bold;
            padding: 12px;
            background: #0a0a0a;
            cursor: pointer;
            list-style: none;
            text-transform: uppercase;
            font-size: 1.1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        details.section[open] > summary {
            border-bottom: 1px solid var(--dim-color);
            color: var(--accent-color);
            text-shadow: var(--crt-glow);
        }

        .section-content { padding: 20px; }

        .subsection {
            margin-bottom: 30px;
            border-left: 4px solid var(--dim-color);
            padding-left: 15px;
        }

        .subsection-title {
            background: var(--dim-color);
            color: var(--accent-color);
            padding: 4px 10px;
            font-weight: bold;
            text-transform: uppercase;
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            font-size: 0.95rem;
        }

        .code-block {
            background: #020a02;
            border: 1px dashed var(--dim-color);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.85rem;
            color: var(--accent-color);
            overflow-x: auto;
        }

        .eye-btn {
            background: none;
            border: 1px solid var(--accent-color);
            color: var(--accent-color);
            cursor: pointer;
            padding: 2px 5px;
            display: flex;
            align-items: center;
            opacity: 0.7;
        }
        .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
    </style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
    <summary>
        PREPROCESSING AND ENCODER-DECODERS FOR NODE CLASSIFICATION:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                PRE-PROCESSING:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>1. Node-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Incremental Re-indexing:</strong> Maps sparse identifiers (like IP addresses) to dense, zero-indexed integers.<br>
                <em>Useful & Why:</em> Essential for memory efficiency. It creates a contiguous address block for embeddings, preventing the allocation of massive, empty tensors for non-existent IDs.</li>
                <li><strong>Feature Normalization:</strong> Scales numerical node features using Z-score or Min-Max scaling.<br>
                <em>Useful & Why:</em> Critical for convergence. It prevents features with large magnitudes (like "account balance") from exploding gradients and dominating the learning process.</li>
                <li><strong>Positional Encodings:</strong> Injects structural coordinates (like Laplacian Eigenvectors) into node features.<br>
                <em>Useful & Why:</em> Vital for structure-aware tasks. It allows the model to distinguish between topologically identical subgraphs based on their absolute position in the global graph.</li>
            </ul>

            <p><strong>2. Edge-Level Preprocessing</strong></p>
            <ul>
                <li><strong>Adjacency List Construction:</strong> Converts known positive connections into a compact Coordinate (COO) format.<br>
                <em>Useful & Why:</em> Foundational for computation. It transforms raw source-target pairs into the sparse matrix standard required for optimized GPU message passing.</li>
                <li><strong>Negative Sampling:</strong> Randomly generates "fake" edges (node pairs that do not connect).<br>
                <em>Useful & Why:</em> Mandatory for discriminative learning. Without "fake" examples (Class 0), the model only sees positives (Class 1) and collapses to a trivial "always true" solution.</li>
                <li><strong>Edge Weighting:</strong> Assigns values to existing links based on interaction strength.<br>
                <em>Useful & Why:</em> Adds necessary nuance. It helps the model prioritize significant, high-traffic pathways over weak or incidental connections in dense graphs.</li>
            </ul>

            <p><strong>3. Structural & Task-Specific Methods</strong></p>
            <ul>
                <li><strong>Subgraph Sampling (e.g., SEAL):</strong> Extracts localized subgraphs around target edge pairs.<br>
                <em>Useful & Why:</em> Enables scaling. It allows training on massive datasets (like social networks) by processing manageable local neighborhoods instead of the entire graph at once.</li>
                <li><strong>Virtual Nodes:</strong> Adds a global dummy node connected to all real nodes.<br>
                <em>Useful & Why:</em> Shortcuts long paths. It allows distant nodes to communicate instantly, improving performance on graphs with long chains or disconnected components.</li>
            </ul>

            <p><strong>4. Edge Splitting & Masking (The Final Phase)</strong></p>
            <ul>
                <li><strong>Message-Passing vs. Supervision Edges:</strong> "Message-passing" edges build the topology; "supervision" edges are hidden for loss calculation.<br>
                <em>Useful & Why:</em> Prevents data leakage. It ensures the model predicts links based on surrounding context, rather than "cheating" by seeing the target link in the input graph.</li>
                <li><strong>Edge Splits (Train/Val/Test):</strong> Positive and negative edges are strictly partitioned.<br>
                <em>Useful & Why:</em> Standard validation. It segregates data to verify the model is learning generalizable patterns rather than simply memorizing the training graph structure.</li>
                <li><strong>Class Balancing:</strong> Ensures a controlled ratio (often 1:1) of positive (real) to negative (fake) edges.<br>
                <em>Useful & Why:</em> Corrects statistical bias. It prevents the model from achieving high accuracy metrics by simply guessing "no link" for every pair in a sparse graph.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR NODE CLASSIFICATION:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>The Foundation: BaseGraphModel</strong></p>
            <p>A template class defining a standard two-layer message-passing flow. It takes a specific convolution layer (like SAGEConv) as an argument and automatically applies a ReLU activation between layers.</p>
            <ul>
                <li><em>How it works:</em> It uses dependency injection. You hand it a "type" of convolution (like a constructor), and it builds the layers for you. This ensures that every model you build follows the same connectivity pattern and dropout rules.</li>
                <li><em>When to use / Why:</em> Use when building multiple GNN architectures. It standardizes the forward pass and reduces boilerplate code across different convolution experiments.</li>
            </ul>
        
            <p><strong>The Simple Implementation: SAGE</strong></p>
            
            <p>GraphSAGE (Sample and Aggregate) plugs directly into the base template. It inherits the structural logic and simply passes SAGEConv as the chosen layer.</p>
            <ul>
                <li><em>How it works:</em> It aggregates features from a fixed-size sample of a node’s neighborhood (e.g., "only look at 10 random friends"). It then concatenates the node's own features with this neighborhood summary. This makes the computation time predictable regardless of how "popular" a node is.</li>
                <li><em>When to use / Why:</em> Use for large, dense graphs. It scales efficiently by sampling fixed-size neighborhoods instead of processing every single connection a node has.</li>
            </ul>
        
            <p><strong>The Custom Implementation: GAT</strong></p>
            
            <p>Graph Attention Networks require custom parameters like attention "heads." GAT manually overrides the constructor to define its layers, multiplying the hidden dimension by the number of attention heads.</p>
            <ul>
                <li><em>How it works:</em> It uses an Attention Mechanism to assign a coefficient (a weight) to every edge. It also uses "Multi-Head Attention," where the model runs several independent attention processes at once (like having 8 different experts looking at the same neighborhood) and then combines their findings.</li>
                <li><em>When to use / Why:</em> Use when edge weights matter but aren't explicitly provided. Attention heads learn which neighbors are most important for the specific task.</li>
            </ul>
        
            <p><strong>Integration: NodeClassifier (The Encoder)</strong></p>
            
            <p>The encoder wraps the chosen model to perform recursive aggregation. Layer 1 captures immediate neighbors. Layer 2 aggregates those results, allowing the center node to "see" a 2-hop radius.</p>
            <ul>
                <li><em>When to use / Why:</em> Use as the core engine for learning topology. It systematically transforms raw node features and local connections into dense, mathematically useful embeddings.</li>
            </ul>
        
            <p><strong>The Decoder: Logarithmic Mapping</strong></p>
            <p>For multi-class node classification, the standard decoder is log_softmax. It outputs a log-probability for each node, optimized using NLLLoss.</p>
            <ul>
                <li><em>When to use / Why:</em> Use for standard multi-class node classification. Operating in log-space stabilizes gradient descent and prevents underflow with extreme probabilities.</li>
            </ul>
        
            <p><strong>Other Decoders for Node Classification Tasks:</strong></p>
            <ul>
                <li><strong>Binary Classification (Sigmoid):</strong> Used for true/false states (e.g., fraudulent vs. legitimate). Outputs a single 0-1 scalar. Optimized with BCELoss.<br>
                <em>When to use / Why:</em> Use for simple A/B sorting. It squashes output to a 0-1 probability score, perfectly pairing with binary cross-entropy loss.</li>
                
                <li><strong>Multi-Label Classification (Independent Sigmoid):</strong> Used when a node belongs to multiple, overlapping categories. Outputs a probability vector. Optimized with BCEWithLogitsLoss.<br>
                <em>When to use / Why:</em> Use when categories overlap (e.g., an entity is both a buyer and seller). It evaluates each class independently rather than forcing a single choice.</li>
                
                <li><strong>Node Regression (Identity/Linear):</strong> Used to predict continuous, real-valued numbers (raw logits). Optimized with MSELoss or L1Loss.<br>
                <em>When to use / Why:</em> Use for predicting continuous metrics (e.g., transaction volume). It passes the raw numerical output directly to calculate absolute error.</li>
                
                <li><strong>Clustering/Unsupervised (Inner Product):</strong> Used without labels. It calculates the dot product of two node embeddings.<br>
                <em>When to use / Why:</em> Use when labels are missing. It forces nodes with similar structural roles or communities to cluster tightly together in the latent embedding space.</li>
            </ul>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        ENCODER-DECODERS FOR LINK PREDICTION
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                ENCODER-DECODER FOR LINK PREDICTION WALKTHROUGH:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>Phase 1: Global Identity Normalization (Indexing)</strong></p>
            <p>Maps raw entity names (like emails or hashes) to contiguous, zero-indexed integers so the GPU can locate them directly in memory. Ecosystems expand this using fast hash functions (like MurmurHash) to convert strings on the fly.</p>
            <ul>
                <li><em>How it works:</em> It assigns every unique raw identifier a sequential integer ID starting from zero. For streaming data, hash functions deterministically map incoming strings to these integer addresses instantly without needing a pre-built static dictionary.</li>
                <li><em>When to use / Why:</em> Use as the mandatory first step for graph building. GPUs cannot process raw strings or sparse, non-sequential IDs. It ensures contiguous memory allocation, preventing massive, empty, and crash-inducing tensors.</li>
            </ul>

            <p><strong>Phase 2: Structural Encoding (edge_index)</strong></p>
            
            <p>Stores graph topology in a 2D tensor (COO format), cleanly separating a node's connections from its actual data features. Advanced setups convert this to CSR formats for extreme speed.</p>
            <ul>
                <li><em>How it works:</em> It creates a 2-by-E matrix where the first row holds source node IDs and the second row holds target node IDs. This Coordinate (COO) format efficiently lists only the edges that actually exist, rather than an N-by-N matrix full of zeros.</li>
                <li><em>When to use / Why:</em> Use for foundational message passing. COO is the standard for PyTorch Geometric to route information between nodes. Converting to CSR is used later when aggressively optimizing dense matrix multiplications in production.</li>
            </ul>

            <p><strong>Phase 3: Feature Matrix Alignment (X)</strong></p>
            
            <p>Ensures strict 1:1 mapping between a node’s new integer ID and its specific row in the dense feature matrix tensor. These vectors can be enriched via PageRank or LLM semantic embeddings.</p>
            <ul>
                <li><em>How it works:</em> It constructs a master feature tensor where row i contains the specific attributes for the node assigned integer ID i. This perfectly aligns the topological map (the edge_index) with the actual node characteristics (the features).</li>
                <li><em>When to use / Why:</em> Use to give the model actual data to learn from beyond just the graph structure. Perfect alignment is critical; a mismatch here means the network is learning from scrambled, incorrect node profiles, rendering the embeddings useless.</li>
            </ul>

            <p><strong>Phase 4: Dataset Splitting & Edge Masking</strong></p>
            
            <p>Hides real "positive" edges for testing, and generates fake "negative" edges so the model learns what non-connections look like. Advanced setups use TemporalData to prevent time-based leaks.</p>
            <ul>
                <li><em>How it works:</em> It splits edges into message-passing (to build the graph) and supervision (to calculate loss). Crucially, it samples random pairs of unconnected nodes to act as negative examples, giving the model a balanced 1:1 classification task.</li>
                <li><em>When to use / Why:</em> Use because real graphs only list positive links. Without generating negative samples, the model collapses into trivially predicting every node pair is connected. Hard negative mining forces the model to learn finer, more accurate boundaries.</li>
            </ul>

            <p><strong>Phase 5: Mini-Batching (Subgraph Generation)</strong></p>
            
            <p>Uses breadth-first search to extract small, localized multi-hop subgraphs, allowing huge networks to fit into GPU memory. Systems use METIS or random walks to control size.</p>
            <ul>
                <li><em>How it works:</em> It pulls a target edge and recursively samples its multi-hop neighborhood to create a self-contained mini-graph. To prevent exponential "neighbor explosion," techniques like GraphSAINT use random walks to strictly bound the subgraph size.</li>
                <li><em>When to use / Why:</em> Use when your graph is too large to fit into VRAM. Standard batching doesn't work for graphs because nodes are connected; subgraph batching preserves the necessary local topology so the model can still aggregate neighbor messages accurately.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                —HETEROGENOUS ENCODERS—
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>In a homogeneous GNN, the model uses one weight matrix. In a heterogeneous graph, the encoder maintains separate weight matrices for each relationship type.</p>
            
            <p><strong>ENCODING APPROACHES:</strong></p>
            <ul>
                <li><strong>1. Identity-based (Lookup Tables):</strong> Assigns a unique, trainable vector to every individual entity. matrix stores one vector per ID. Use this for large-scale Collaborative Filtering with little metadata.</li>
                <li><strong>2. Feature-based (Linear/MLP Projections):</strong> Transforms raw attributes (age, price) into a vector space using a Linear layer or MLP. Appropriate for cold-start scenarios.</li>
                <li><strong>3. Hybrid Fusion (The "Two-Step"):</strong> Merges Identity and Feature methods. Concatenates the "what" (feature) to the "who" (identity). Appropriate for RecSys needing a "warm start."</li>
                <li><strong>4. Contextual/Sequential Encoders:</strong> Models like RNNs or Transformers process sequences of past actions. Use this for session-based recommendations.</li>
            </ul>

            <p><strong>DECODER APPROACHES:</strong></p>
            <ul>
                <li><strong>1. Dot Product (Similarity-Based):</strong> Computes similarity between user and item vectors. Critical for large-scale retrieval efficiency.</li>
                <li><strong>2. Multi-Layer Perceptron (MLP) (Non-Linear):</strong> Concatenates embeddings and passes them through a neural network. Used for high-precision ranking.</li>
                <li><strong>3. TransE (Translational Distance):</strong> Treats relationship as translation: h + r ≈ t. Ideal for knowledge graphs with logical flow.</li>
                <li><strong>4. DistMult (Multiplicative Interaction):</strong> Relationship as diagonal matrix M_r. Score = h_i^T M_r h_j. Performs element-wise multiplication weighted by relationship importance.</li>
            </ul>
        </div>
    </div>
</details>

</body>
</html>