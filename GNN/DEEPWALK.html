<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* --- INTEGRATED CRT CORE STYLES --- */
        :root {
            --bg-color: #000000;
            --text-color: #00ff41;
            --accent-color: #00ff41;
            --dim-color: #003b00;
            --border-color: #00ff41;
            --font-main: 'Courier New', Courier, monospace;
            --font-header: 'Arial Black', Impact, sans-serif;
            --crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--font-main);
            margin: 0;
            padding: 20px;
            line-height: 1.5;
        }

        /* --- VISUAL EFFECTS --- */
        .dither-layer {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
            background-size: 4px 4px;
            opacity: 0.4;
        }

        .scanlines {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
            background-size: 100% 4px;
            pointer-events: none;
            z-index: 9999;
        }

        /* --- MODULE COMPONENTS --- */
        strong { color: var(--accent-color); text-decoration: underline; }
        em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

        details.section {
            margin-bottom: 15px;
            border: 1px solid var(--dim-color);
            background: #050505;
        }

        details.section > summary {
            font-weight: bold;
            padding: 12px;
            background: #0a0a0a;
            cursor: pointer;
            list-style: none;
            text-transform: uppercase;
            font-size: 1.1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        details.section[open] > summary {
            border-bottom: 1px solid var(--dim-color);
            color: var(--accent-color);
            text-shadow: var(--crt-glow);
        }

        .section-content { padding: 20px; }

        .subsection {
            margin-bottom: 30px;
            border-left: 4px solid var(--dim-color);
            padding-left: 15px;
        }

        .subsection-title {
            background: var(--dim-color);
            color: var(--accent-color);
            padding: 4px 10px;
            font-weight: bold;
            text-transform: uppercase;
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            font-size: 0.95rem;
        }

        .code-block {
            background: #020a02;
            border: 1px dashed var(--dim-color);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.85rem;
            color: var(--accent-color);
            overflow-x: auto;
        }

        .eye-btn {
            background: none;
            border: 1px solid var(--accent-color);
            color: var(--accent-color);
            cursor: pointer;
            padding: 2px 5px;
            display: flex;
            align-items: center;
            opacity: 0.7;
        }
        .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
    </style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
    <summary>
        NODE REPRESENTATIONS WITH DEEPWALK
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
    </summary>
    
    <div class="section-content">
        <p><em>PRECURSORS NECESSARY TO UNDERSTAND DEEPWALK:</em></p>
        
        <div class="subsection">
            <span class="subsection-title">
                THE WORKFLOW: FROM RANDOM WALKS TO OPTIMIZED VECTORS
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>Summary:</strong> Skip-gram defines what the model learns (neighbor relationships). Softmax is the mathematical goal (probability distribution). H-Softmax is the optimization structure that makes calculating that probability feasible for massive datasets.</p>
            
            <ul>
                <li><strong>1. Data Generation (Skip-gram Setup):</strong> The process begins with Random Walks on your graph. These walks generate the training data: pairs of nodes consisting of a Target Node (the focus) and a Context Node (a neighbor found in the walk). Task: "Given Target Node A, predict that Context Node B is its neighbor."</li>
                
                <li><strong>2. Forward Pass (Projection):</strong> The model accepts the unique ID of Target Node A. It looks up Node A's current Input Vector in the Projection Layer (Embedding Matrix). This vector represents Node A's current position in the high-dimensional space.</li>
                
                <li><strong>3. The Prediction Problem (The Bottleneck):</strong> Now, the model must determine the probability that Node B is the correct neighbor.
                    <ul>
                        <li><em>Standard Softmax (The Slow Way):</em> To do this normally, the model calculates the dot product of Node A's vector against every other node in the graph to see which score is highest. It then applies Softmax to normalize these scores. For a graph with millions of nodes, calculating millions of dot products for every single training step is impossibly slow (O(|V|)).</li>
                    </ul>
                </li>
                
                <li><strong>4. The Solution (H-Softmax Integration):</strong> To fix the speed issue, Hierarchical Softmax replaces the flat output layer with a Binary Huffman Tree.
                    <ul>
                        <li><em>Restructuring:</em> All nodes in the graph are placed as "leaves" at the bottom of this tree. Common nodes (hubs) are placed near the top; rare nodes are placed deeper.</li>
                        <li><em>The Root:</em> Think of the root as a binary classifier. It holds a unique weight vector &theta;<sub>root</sub> of the same dimensionality as your node embeddings. It is learned via Backpropagation.</li>
                        <li><em>The New Task:</em> Instead of comparing Node A against everyone, the model navigates the tree. To predict Node B, it only needs to calculate the probability of taking the correct sequence of binary turns (e.g., Left &rarr; Right &rarr; Left) to reach Node B from the root.</li>
                        <li><em>Efficiency:</em> This reduces the complexity from checking millions of nodes to checking just the tree depth (roughly log<sub>2</sub>(|V|)).</li>
                    </ul>
                </li>
                
                <li><strong>5. Optimization (Backpropagation):</strong> The model calculates the error based on the path taken. If the probability of turning "Left" at a specific branch was low but should have been high, the model applies Backpropagation. This updates the Input Vector of Target Node A. It also updates the weights of the internal branch nodes along that specific path.</li>
            </ul>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        DEEPWALK
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.1</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                Overview
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <ul>
                <li><strong>How It Works:</strong> DeepWalk treats a graph like a corpus of text. It uses Random Walks to transform the network's topology into "sentences" of node IDs. These sequences are fed into a Skip-gram model (originally from Word2Vec). By maximizing the local community's probability through Hierarchical Softmax, the model forces nodes that frequently appear together in walks to have similar vector representations in a low-dimensional space.</li>
                
                <li><strong>Why Use It:</strong> It solves the "dimensionality curse" of massive adjacency matrices. DeepWalk is computationally efficient ($O(\log |V|)$ per step), making it feasible for graphs with millions of nodes. Unlike traditional methods, it doesn't require the entire graph to be in memory simultaneously. It captures latent social dimensions—the hidden community structures—that simple neighbor-counting misses, leading to better downstream performance.</li>
                
                <li><strong>When To Use It:</strong> Use DeepWalk when you have a large, unweighted, or undirected graph and need baseline embeddings for tasks like node classification or community detection. It is ideal for unsupervised scenarios where you lack labeled data but want to preserve structural similarity. While newer models like Node2vec offer more flexibility, DeepWalk remains the "gold standard" for a fast, reliable, and "set-it-and-forget-it" graph embedding strategy.</li>
            </ul>
        </div>
    </div>
</details>

</body>
</html>