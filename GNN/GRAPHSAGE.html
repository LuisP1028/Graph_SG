<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>
        /* --- INTEGRATED CRT CORE STYLES --- */
        :root {
            --bg-color: #000000;
            --text-color: #00ff41;
            --accent-color: #00ff41;
            --dim-color: #003b00;
            --border-color: #00ff41;
            --font-main: 'Courier New', Courier, monospace;
            --font-header: 'Arial Black', Impact, sans-serif;
            --crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
        }

        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: var(--font-main);
            margin: 0;
            padding: 20px;
            line-height: 1.5;
        }

        /* --- VISUAL EFFECTS --- */
        .dither-layer {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            z-index: -1;
            background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
            background-size: 4px 4px;
            opacity: 0.4;
        }

        .scanlines {
            position: fixed;
            top: 0; left: 0; width: 100%; height: 100%;
            background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
            background-size: 100% 4px;
            pointer-events: none;
            z-index: 9999;
        }

        /* --- MODULE COMPONENTS --- */
        strong { color: var(--accent-color); text-decoration: underline; }
        em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

        details.section {
            margin-bottom: 15px;
            border: 1px solid var(--dim-color);
            background: #050505;
        }

        details.section > summary {
            font-weight: bold;
            padding: 12px;
            background: #0a0a0a;
            cursor: pointer;
            list-style: none;
            text-transform: uppercase;
            font-size: 1.1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }

        details.section[open] > summary {
            border-bottom: 1px solid var(--dim-color);
            color: var(--accent-color);
            text-shadow: var(--crt-glow);
        }

        .section-content { padding: 20px; }

        .subsection {
            margin-bottom: 30px;
            border-left: 4px solid var(--dim-color);
            padding-left: 15px;
        }

        .subsection-title {
            background: var(--dim-color);
            color: var(--accent-color);
            padding: 4px 10px;
            font-weight: bold;
            text-transform: uppercase;
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
            font-size: 0.95rem;
        }

        .code-block {
            background: #020a02;
            border: 1px dashed var(--dim-color);
            padding: 10px;
            margin: 10px 0;
            font-size: 0.85rem;
            color: var(--accent-color);
            overflow-x: auto;
        }

        .eye-btn {
            background: none;
            border: 1px solid var(--accent-color);
            color: var(--accent-color);
            cursor: pointer;
            padding: 2px 5px;
            display: flex;
            align-items: center;
            opacity: 0.7;
        }
        .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
    </style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
    <summary>
        ADVANCED GNN ARCHITECTURES
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                PRE REQS:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>Goal:</strong> In practice, the graph is built by expanding x‚Äôs neighborhood to k hops.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                Computation Graph:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <ul>
                <li><strong>Key 01:</strong> Computation flows inward: Leaf nodes (at distance K) pass features to their neighbors at ùêæ‚àíùüè, which aggregate and transform them.</li>
                <li><strong>Key 02:</strong> This repeats until produces a final embedding from its 1-hop neighbors.</li>
            </ul>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        GRAPHSAGE:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                Its goal
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>Goal:</strong> GraphSAGE is designed to process massive networks. It generates <strong>node embeddings</strong>‚Äîdense mathematical representations of a node's local network and features‚Äîwhich are then used downstream for tasks like predicting a node's category (node classification). </p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                1. Neighbor sampling:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <ul>
                <li><strong>Mechanism:</strong> In huge graphs, some nodes have an overwhelming number of connections (hub nodes). GraphSAGE manages this by limiting the data it pulls.</li>
                <li><strong>Strategy:</strong> Instead of aggregating data from <em>every</em> neighbor, it randomly samples a fixed number of neighbors per connection jump (hop).</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                Tradeoffs of low sampling numbers:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Sampling fewer neighbors uses less memory and speeds up training. However, it increases variance; you might randomly exclude crucial neighbors, causing noisy gradients, unstable training, and potentially reduced accuracy.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                PinSAGE:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Instead of uniform random sampling, PinSAGE takes multiple simulated "random walks" starting from a node. It selects the neighbors visited most often during these walks. This <strong>importance-based sampling</strong> guarantees that structurally critical nodes are chosen, which is highly effective for recommendation systems.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                2. Aggregation:
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            
            <p><strong>Mean Aggregator:</strong> The simplest route. It calculates the average of the target node's data and its sampled neighbors. This average is multiplied by a learned weight matrix and passed through a non-linear filter (like ReLU). <br><em>Best for:</em> Fast, general-purpose efficiency.</p>
            
            <p><strong>LSTM Aggregator:</strong> Uses a neural network architecture (LSTM) to decode highly complex interactions. Because graph neighbors don't have a natural sequence, GraphSAGE randomly shuffles them before feeding them to the LSTM. This forces the model to learn patterns from the set as a whole, rather than relying on order. <br><em>Best for:</em> Graphs with intricate, non-linear dependencies.</p>
            
            <p><strong>Pooling Aggregator:</strong> A two-step "winner-take-all" method. First, a Multi-Layer Perceptron (MLP) transforms each neighbor's raw embedding to highlight key traits. Second, an <strong>element-wise max pooling</strong> operation scans each data dimension and keeps only the highest value across the entire neighborhood. <br><em>Best for:</em> Isolating the strongest, most dominant signals in a neighborhood.</p>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        GRAPHSAGE NODE CLASSIFICATION WALKTHROUGH:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                1. Data Preparation & Loading
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Initialize your graph dataset. In PyTorch Geometric (PyG), this involves defining node features ($x$), connectivity (edge_index), and ground-truth labels ($y$). For multi-class tasks, ensure labels are mapped to discrete integers.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                2. Neighbor Sampling
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>For large-scale graphs, use a <em>NeighborLoader</em> to generate subgraphs. This is critical for scalability as it creates "computation graphs" for small batches of target nodes. <strong>Sampling Strategy:</strong> Specify num_neighbors (e.g., $[10, 10]$ for two layers) to control the size of each node's sampled neighborhood. <strong>Batching:</strong> Group target nodes into manageable sizes (e.g., batch_size=16) to process the graph iteratively.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                3. Model Architecture
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Define a GraphSAGE class inheriting from torch.nn.Module using SAGEConv layers. <strong>Aggregator Choice:</strong> By default, SAGEConv uses a mean aggregator. You can switch this to pooling (max-pooling after an MLP transformation) or LSTM (using random permutations to handle unordered sets) depending on your structural complexity needs. <strong>Layer Stacking:</strong> Use multiple layers (e.g., sage1, sage2) to capture multi-hop dependencies, separated by non-linear activations like ReLU and Dropout to prevent overfitting.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                4. Training Pipeline
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Adapt your training loop to handle batches. <strong>Forward Pass:</strong> Pass the batch's features and edges through the model. <strong>Loss Calculation:</strong> Apply a loss function (e.g., CrossEntropyLoss) specifically to the train_mask of the current batch. <strong>Metric Tracking:</strong> Accumulate loss and accuracy across all batches to represent the total epoch performance.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                5. Evaluation & Testing
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p>Switch the model to .eval() mode. While training uses sampled batches, evaluation can be performed on the full graph if memory allows, or through a dedicated test loader for massive datasets.</p>
        </div>
    </div>
</details>

<details class="section">
    <summary>
        GRAPHSAGE NODE MULTI-LABEL CLASSIFICATION WALKTHROUGH:
        <span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
    </summary>
    
    <div class="section-content">
        <div class="subsection">
            <span class="subsection-title">
                1. Data Organization & Unification
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>The Choice:</strong> Use Batch.from_data_list() to unify disjoint graphs during training.</p>
            <p><strong>The Reasoning:</strong> Many real-world applications (like protein modeling) provide multiple separate graphs. Unifying them allows you to treat a "forest" of graphs as one large adjacency matrix, enabling consistent neighbor sampling across the entire training set rather than processing one tiny graph at a time.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                2. Sampling & Stochastic Loading
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>The Choice:</strong> Implement NeighborLoader with defined sampling depths (e.g., num_neighbors=[20, 10]).</p>
            <p><strong>The Reasoning:</strong> This transforms the graph into a set of local computation graphs. By limiting neighbors, you fix the memory footprint, ensuring the model can scale to massive datasets (like social networks) where loading the full graph into GPU memory is impossible.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                3. Aggregator Selection (SAGEConv)
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <ul>
                <li><strong>Mean Aggregator:</strong> Best for general node classification where the average context of neighbors is sufficient. It is computationally efficient and easy to interpret.</li>
                <li><strong>Pooling Aggregator:</strong> Best for identifying "dominant" features or outliers. By using an MLP transformation before max-pooling, the model learns to highlight the most salient signals in a neighborhood, which is effective in recommendation systems.</li>
                <li><strong>LSTM Aggregator:</strong> Best for complex, non-linear structural patterns. Because it uses random permutations, it learns to treat neighbors as a "set" while maintaining high expressive power to distinguish between intricate graph isomorphisms.</li>
            </ul>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                4. Loss Functions & Multi-Label Logic
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>The Choice:</strong> Use BCEWithLogitsLoss for multi-label tasks.</p>
            <p><strong>The Reasoning:</strong> Unlike CrossEntropyLoss (which assumes only one "correct" class), Binary Cross Entropy treats each of the 121 possible labels as an independent binary prediction. This is essential for applications like document tagging, where a node can belong to multiple categories simultaneously.</p>
        </div>

        <div class="subsection">
            <span class="subsection-title">
                5. Performance Metrics (F1 Score)
                <button class="eye-btn">
                    <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                        <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                        <circle cx="12" cy="12" r="3"></circle>
                    </svg>
                </button>
            </span>
            <p><strong>The Choice:</strong> Thresholding outputs at out > 0 and calculating a Micro-F1 Score.</p>
            <p><strong>The Reasoning:</strong> In multi-label settings, simple accuracy is often misleadingly high if most labels are "0". The F1 score balances precision and recall, while micro-averaging ensures that rare labels are given appropriate weight in the final performance metric.</p>
        </div>
    </div>
</details>

</body>
</html>