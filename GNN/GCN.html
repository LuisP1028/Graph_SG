<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
/* --- INTEGRATED CRT CORE STYLES --- */
:root {
--bg-color: #000000;
--text-color: #00ff41;
--accent-color: #00ff41;
--dim-color: #003b00;
--border-color: #00ff41;
--font-main: 'Courier New', Courier, monospace;
--font-header: 'Arial Black', Impact, sans-serif;
--crt-glow: 0px 0px 8px rgba(0, 255, 65, 0.4);
}

    body {
        background-color: var(--bg-color);
        color: var(--text-color);
        font-family: var(--font-main);
        margin: 0;
        padding: 20px;
        line-height: 1.5;
    }

    /* --- VISUAL EFFECTS --- */
    .dither-layer {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        z-index: -1;
        background-image: radial-gradient(circle, #003b00 1px, transparent 1px);
        background-size: 4px 4px;
        opacity: 0.4;
    }

    .scanlines {
        position: fixed;
        top: 0; left: 0; width: 100%; height: 100%;
        background: linear-gradient(to bottom, rgba(0, 255, 65, 0), rgba(0, 255, 65, 0) 50%, rgba(0, 20, 0, 0.2) 50%, rgba(0, 20, 0, 0.2));
        background-size: 100% 4px;
        pointer-events: none;
        z-index: 9999;
    }

    /* --- MODULE COMPONENTS --- */
    strong { color: var(--accent-color); text-decoration: underline; }
    em { font-style: normal; color: #50c878; border-bottom: 1px dotted var(--dim-color); }

    details.section {
        margin-bottom: 15px;
        border: 1px solid var(--dim-color);
        background: #050505;
    }

    details.section > summary {
        font-weight: bold;
        padding: 12px;
        background: #0a0a0a;
        cursor: pointer;
        list-style: none;
        text-transform: uppercase;
        font-size: 1.1rem;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }

    details.section[open] > summary {
        border-bottom: 1px solid var(--dim-color);
        color: var(--accent-color);
        text-shadow: var(--crt-glow);
    }

    .section-content { padding: 20px; }

    .subsection {
        margin-bottom: 30px;
        border-left: 4px solid var(--dim-color);
        padding-left: 15px;
    }

    .subsection-title {
        background: var(--dim-color);
        color: var(--accent-color);
        padding: 4px 10px;
        font-weight: bold;
        text-transform: uppercase;
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 15px;
        font-size: 0.95rem;
    }

    .code-block {
        background: #020a02;
        border: 1px dashed var(--dim-color);
        padding: 10px;
        margin: 10px 0;
        font-size: 0.85rem;
        color: var(--accent-color);
        overflow-x: auto;
    }

    .eye-btn {
        background: none;
        border: 1px solid var(--accent-color);
        color: var(--accent-color);
        cursor: pointer;
        padding: 2px 5px;
        display: flex;
        align-items: center;
        opacity: 0.7;
    }
    .eye-btn:hover { opacity: 1; background: var(--accent-color); color: black; }
</style>
</head>
<body>

<div class="dither-layer"></div>
<div class="scanlines"></div>

<details class="section" open>
<summary>
GRAPH CONVOLUTIONAL NETWORKS
<span style="color: var(--dim-color); font-size: 0.8rem;">MODULE_V1.0</span>
</summary>

<div class="section-content">
    
    <div class="subsection">
        <span class="subsection-title">
            Feature Smoothing
            <button class="eye-btn">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                    <circle cx="12" cy="12" r="3"></circle>
                </svg>
            </button>
        </span>
        
        <p><strong>Goal:</strong> Compared to the vanilla GNN, the main feature of the GCN is that it considers node degrees to weigh its features.</p>
        
        <ul>
            <li><strong>Key 01:</strong> The scale problem in Graph Neural Networks (GNNs), popular nodes produce massive values while "loners" produce tiny ones.</li>
            <li><strong>Key 02:</strong> This variance makes it impossible for the model to compare embeddings or learn effectively.</li>
            <li><strong>Key 03:</strong> To solve this, we normalize the aggregation. The degree matrix () tracks how many neighbors each node has.</li>
            <li><strong>Key 04:</strong> By multiplying the adjacency matrix by the inverse degree matrix (¹), we transform the “sum” into a mean.</li>
        </ul>
    </div>

    <div class="subsection">
        <span class="subsection-title">
            The Power of Self-Loops and Normalization
            <button class="eye-btn">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                    <circle cx="12" cy="12" r="3"></circle>
                </svg>
            </button>
        </span>
        <p><strong>Goal:</strong> Adding self-loops ( = + ): Ensures that a node’s own features are included during the aggregation step.</p>
        <ul>
            <li><strong>Key 01:</strong> Without them, a node would only “know” about its neighbors, effectively losing its own identity in every layer.</li>
            <li><strong>Key 02:</strong> Symmetric normalization: Prevents "hub" nodes with massive connectivity from over-powering the network.</li>
            <li><strong>Key 03:</strong> By factoring in both the sender's and receiver's degrees, it scales down signals from high-degree nodes and boosts those from isolated ones.</li>
        </ul>
    </div>

    <div class="subsection">
        <span class="subsection-title">
            GCN Layers
            <button class="eye-btn">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                    <circle cx="12" cy="12" r="3"></circle>
                </svg>
            </button>
        </span>
        <p><strong>Goal:</strong> In deep learning, a layer is a mathematical transformation that maps input features to a new representation.</p>
        <ul>
            <li><strong>Key 01:</strong> A graph layer (GCN layer) is unique because its transformation depends on two things: the node features () and the graph structure ().</li>
            <li><strong>Key 02:</strong> Linear Transformation: Features are multiplied by a weight matrix () to extract relevant patterns.</li>
            <li><strong>Key 03:</strong> Aggregation: Each node gathers features from its neighbors.</li>
            <li><strong>Key 04:</strong> Normalization: This sum is scaled using the degrees of the sender and receiver (1/deg(i)deg(j)) to keep values stable.</li>
            <li><strong>Key 05:</strong> Activation functions: Applied to each dimension of a node's embedding.</li>
        </ul>
    </div>

    <div class="subsection">
        <span class="subsection-title">
            GCN GENERAL SETUP
            <button class="eye-btn">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                    <circle cx="12" cy="12" r="3"></circle>
                </svg>
            </button>
        </span>
        <p><strong>Goal:</strong> 1. Define the Architecture: You create a class inheriting from torch.nn.Module.</p>
        <ul>
            <li><strong>Key 01:</strong> Unlike standard networks, you instantiate GCNConv layers which require both node features and the graph structure (edge_index) during the forward pass.</li>
            <li><strong>Key 02:</strong> Layer 1: Performs the "message pass" (aggregating neighbor info to the current node) and projects it to a higher dimensional space.</li>
            <li><strong>Key 03:</strong> Activation: An activation function adds non-linearity, allowing the model to learn complex patterns.</li>
            <li><strong>Key 04:</strong> Layer 2: Performs a message pass using the embeddings. Since those neighbors already gathered information from their neighbors in the first layer, the second layer effectively enables each node to capture information from n-hops away.</li>
            <li><strong>Key 05:</strong> (Hops defined as the number of GCN layers used)</li>
            <li><strong>Key 06:</strong> 2. The Training Loop (fit): The training process uses standard optimizers like Adam, but the loss is typically calculated only on a specific mask (e.g., train_mask).</li>
            <li><strong>Key 07:</strong> 3. Application Versatility: Node Classification (Cora dataset), Link Prediction, and Graph Classification (using pooling).</li>
        </ul>
    </div>

    <div class="subsection">
        <span class="subsection-title">
            GCN NODE REGRESSION SETUP
            <button class="eye-btn">
                <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path>
                    <circle cx="12" cy="12" r="3"></circle>
                </svg>
            </button>
        </span>
        <p><strong>Goal:</strong> Using an encoder-style architecture to distill raw graph data into a single continuous prediction.</p>
        <ul>
            <li><strong>Key 01:</strong> By stacking three GCNConv layers with decreasing dimensions ( ), the network creates a bottleneck that forces it to learn only the most impactful structural patterns.</li>
            <li><strong>Key 02:</strong> • Three-Hop Context: Three layers expand the receptive field to 3 hops, letting each node “see” a wide area of the Wikipedia network to inform its prediction.</li>
            <li><strong>Key 03:</strong> • Regression Head: A final Linear layer maps hidden features to a single scalar (dimension ) without a softmax, allowing for unbounded numerical output.</li>
            <li><strong>Key 04:</strong> • Training Goal: Mean Squared Error (MSE) loss replaces classification loss, penalizing the squared difference between the predicted and actual log-traffic.</li>
        </ul>
    </div>

</div>
</details>

</body>
</html>